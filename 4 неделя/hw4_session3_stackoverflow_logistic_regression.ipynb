{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Не удается найти указанный файл",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8ede756c42f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-125>\u001b[0m in \u001b[0;36mwatermark\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\watermark\\watermark.py\u001b[0m in \u001b[0;36mwatermark\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    127\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'\\nhost name%s: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgethostname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgithash\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_commit_hash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmachine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgitrepo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_git_remote_origin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmachine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\watermark\\watermark.py\u001b[0m in \u001b[0;36m_get_commit_hash\u001b[1;34m(self, machine)\u001b[0m\n\u001b[0;32m    194\u001b[0m         process = subprocess.Popen(['git', 'rev-parse', 'HEAD'],\n\u001b[0;32m    195\u001b[0m                                    \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                                    stdout=subprocess.PIPE)\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mgit_head_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    674\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\user\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    955\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    958\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Не удается найти указанный файл"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = 'stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = 'top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'php', 'c#', 'java', 'ios', 'python', 'c++', 'android', 'jquery', 'html', 'javascript'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$ +\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$+\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'android',\n",
       " 'c#',\n",
       " 'c++',\n",
       " 'html',\n",
       " 'ios',\n",
       " 'java',\n",
       " 'javascript',\n",
       " 'jquery',\n",
       " 'php',\n",
       " 'python'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = 1/(1+np.exp(-z)) if z>=0 else 1-1/(1+np.exp(z))                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sample_loss-=(1 - y) * np.log(max(tolerance, 1-sigma)) + y * np.log(max(tolerance, sigma))                                                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y-sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\", line 148, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAK9CAYAAADCGvq3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x57445c7278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 20.07\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74 +\n",
    "4. 20.84 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        accur = []\n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                test_tags = []\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    sigma = 1/(1+np.exp(-z)) if z>=0 else 1-1/(1+np.exp(z)) \n",
    "                    if sigma > 0.9 :\n",
    "                        test_tags.append(tag)\n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    #если текущий тег есть у текущего параметра, то считаем максимум\n",
    "                    sample_loss-=(1 - y) * np.log(max(tolerance, 1-sigma)) + y * np.log(max(tolerance, sigma))                                                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y-sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                if(n > top_n_train):\n",
    "                    temp = len(tags.intersection(test_tags))/len(tags.union(test_tags))\n",
    "                    accur.append(temp)\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "            return np.mean(accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59 +\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
